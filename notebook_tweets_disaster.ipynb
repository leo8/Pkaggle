{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b869fa",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294d328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da381c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings\n",
    "\n",
    "from sentence_transformers import util, SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811665fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep learning\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324fd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0456e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT for Sequence Classification\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cac0f3",
   "metadata": {},
   "source": [
    "# Import des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02d0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "329023fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b86943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f14827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb0401",
   "metadata": {},
   "source": [
    "### Split training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a51c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e6db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3339e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab1839",
   "metadata": {},
   "source": [
    "### Resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108c4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f432925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10810</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>6</td>\n",
       "      <td>@Tunes_WGG lol. U got wrecked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cop pulls drunk driver to safety SECONDS befor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1607</td>\n",
       "      <td>bombed</td>\n",
       "      <td>MY RTs ARE NOT ENDORSEMENTS</td>\n",
       "      <td>@ChristophersZen @HunterLove1995 @tblack yeah ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589</td>\n",
       "      <td>arson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tennessee lesbian couple faked hate crime and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3900</td>\n",
       "      <td>devastated</td>\n",
       "      <td>PG Chillin!</td>\n",
       "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      keyword                     location  \\\n",
       "0  10810      wrecked                            6   \n",
       "1    313  annihilated                          NaN   \n",
       "2   1607       bombed  MY RTs ARE NOT ENDORSEMENTS   \n",
       "3    589        arson                          NaN   \n",
       "4   3900   devastated                  PG Chillin!   \n",
       "\n",
       "                                                text  target  \n",
       "0                      @Tunes_WGG lol. U got wrecked       0  \n",
       "1  Cop pulls drunk driver to safety SECONDS befor...       1  \n",
       "2  @ChristophersZen @HunterLove1995 @tblack yeah ...       0  \n",
       "3  Tennessee lesbian couple faked hate crime and ...       1  \n",
       "4  Man Currensy really be talkin that talk... I'd...       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04e231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f527c53",
   "metadata": {},
   "source": [
    "### Separating X and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2facf0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1191684",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d794d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0139e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d9a52",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d9eefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a1775b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keyword.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f450710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.location.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1e9f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_full_text = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    full_text = data['text'][i]\n",
    "    if str(data['keyword'][i]) != 'nan':\n",
    "        full_text += f' #{data[\"keyword\"][i]}'\n",
    "    if str(data['location'][i]) != 'nan':\n",
    "        full_text += f' #{data[\"location\"][i]}'\n",
    "\n",
    "    l_full_text.append(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78efc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['full_text'] = pd.Series(l_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df2344d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                          full_text  \n",
       "0       1  Our Deeds are the Reason of this #earthquake M...  \n",
       "1       1             Forest fire near La Ronge Sask. Canada  \n",
       "2       1  All residents asked to 'shelter in place' are ...  \n",
       "3       1  13,000 people receive #wildfires evacuation or...  \n",
       "4       1  Just got sent this photo from Ruby #Alaska as ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88172477",
   "metadata": {},
   "source": [
    "Apr√®s quelques essais, les embeddings de full_text offrent de moins bons r√©sultats de pr√©diction que ceux du texte simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510950d8",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eada19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3025db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = transformer.encode(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6e42f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0ae147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings = transformer.encode(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e12a4",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1398d",
   "metadata": {},
   "source": [
    "### Convert embeddings and target to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a22c4583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 17:44:19.563600: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-29 17:44:19.563717: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "tensor_embeddings = tf.convert_to_tensor(embeddings)\n",
    "tensor_y = tf.convert_to_tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e7b17f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6851, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0444a96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6851])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede12669",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_val_embeddings = tf.convert_to_tensor(val_embeddings)\n",
    "tensor_val_y = tf.convert_to_tensor(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd82a7",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfe1e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff15ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "397f8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Define model architecture.\n",
    "model.add(Dense(728, input_shape=(768,), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e09ac0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 728)               559832    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 728)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               186624    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 762,969\n",
      "Trainable params: 762,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c4ea018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer, #or optimizer\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431dccc",
   "metadata": {},
   "source": [
    "### Training and performances visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39b13247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 17:44:19.698334: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-29 17:44:19.896703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 2s 8ms/step - loss: 0.4461 - accuracy: 0.8062 - val_loss: 0.4457 - val_accuracy: 0.8084 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "  1/215 [..............................] - ETA: 2s - loss: 0.2819 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 17:44:21.752529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3811 - accuracy: 0.8419 - val_loss: 0.4610 - val_accuracy: 0.8150 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3366 - accuracy: 0.8577 - val_loss: 0.4710 - val_accuracy: 0.7979 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2954 - accuracy: 0.8758 - val_loss: 0.5309 - val_accuracy: 0.8176 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2411 - accuracy: 0.8987 - val_loss: 0.6535 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "211/215 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9196\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1927 - accuracy: 0.9199 - val_loss: 0.6325 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1296 - accuracy: 0.9473 - val_loss: 0.7517 - val_accuracy: 0.7953 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "213/215 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9617\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0946 - accuracy: 0.9616 - val_loss: 0.9193 - val_accuracy: 0.7927 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0650 - accuracy: 0.9758 - val_loss: 0.9970 - val_accuracy: 0.7966 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "208/215 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9781\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0594 - accuracy: 0.9778 - val_loss: 1.0059 - val_accuracy: 0.7979 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0477 - accuracy: 0.9791 - val_loss: 1.1305 - val_accuracy: 0.8005 - lr: 1.2500e-04\n",
      "Epoch 12/20\n",
      "212/215 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9816\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0463 - accuracy: 0.9816 - val_loss: 1.1227 - val_accuracy: 0.8018 - lr: 1.2500e-04\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0386 - accuracy: 0.9850 - val_loss: 1.1610 - val_accuracy: 0.8005 - lr: 6.2500e-05\n",
      "Epoch 14/20\n",
      "209/215 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9831\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0390 - accuracy: 0.9834 - val_loss: 1.1876 - val_accuracy: 0.7992 - lr: 6.2500e-05\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 1.1890 - val_accuracy: 0.8005 - lr: 3.1250e-05\n",
      "Epoch 16/20\n",
      "214/215 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9853\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0350 - accuracy: 0.9853 - val_loss: 1.2169 - val_accuracy: 0.8018 - lr: 3.1250e-05\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0351 - accuracy: 0.9839 - val_loss: 1.2185 - val_accuracy: 0.8018 - lr: 1.5625e-05\n",
      "Epoch 18/20\n",
      "212/215 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9857\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0343 - accuracy: 0.9855 - val_loss: 1.2183 - val_accuracy: 0.8045 - lr: 1.5625e-05\n",
      "Epoch 19/20\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0324 - accuracy: 0.9855 - val_loss: 1.2236 - val_accuracy: 0.8018 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0322 - accuracy: 0.9860 - val_loss: 1.2290 - val_accuracy: 0.8018 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=tensor_embeddings,\n",
    "    y=tensor_y,\n",
    "    validation_data=(tensor_val_embeddings, tensor_val_y),\n",
    "    callbacks=[learning_rate_reduction],\n",
    "    epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b54d8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(history, model_name):\n",
    "    \n",
    "    fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "    \n",
    "    epochs_nb = history.params['epochs']\n",
    "    \n",
    "    ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax_loss.set_title(f'Loss history of {model_name} over {epochs_nb} epochs')\n",
    "    ax_loss.set_xlabel('Number of epochs')\n",
    "    ax_loss.set_ylabel('Loss')\n",
    "    ax_loss.legend()\n",
    "    \n",
    "    ax_acc.plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\n",
    "    ax_acc.plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "    ax_acc.set_title(f'Accuracy history of {model_name} over {epochs_nb} epochs')\n",
    "    ax_acc.set_xlabel('Number of epochs')\n",
    "    ax_acc.set_ylabel('Accuracy')\n",
    "    ax_acc.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb76eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_results(history, 'basic_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfe83a",
   "metadata": {},
   "source": [
    "# Classifier approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0945c5",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc32d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b2b71c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3702802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.997372646329003"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ac9c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7965879265091863"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(val_embeddings, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2887e7",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dce36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0af757f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3189            1.74m\n",
      "         2           1.2801            1.72m\n",
      "         3           1.2448            1.70m\n",
      "         4           1.2127            1.68m\n",
      "         5           1.1824            1.67m\n",
      "         6           1.1562            1.65m\n",
      "         7           1.1316            1.63m\n",
      "         8           1.1093            1.61m\n",
      "         9           1.0884            1.59m\n",
      "        10           1.0700            1.58m\n",
      "        20           0.9328            1.40m\n",
      "        30           0.8509            1.24m\n",
      "        40           0.7958            1.07m\n",
      "        50           0.7534           53.57s\n",
      "        60           0.7201           43.05s\n",
      "        70           0.6917           32.39s\n",
      "        80           0.6678           21.76s\n",
      "        90           0.6485           10.93s\n",
      "       100           0.6313            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c99eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766603415559773"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c503f0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175853018372703"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.score(val_embeddings, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8274cc",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbda59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'n_estimators': [100, 300, 500, 1000],\n",
    "               'max_depth': [300, 500, 1000]\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c1710",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b064077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=100; total time=   8.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=100; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=100; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=100; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=100; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  23.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   39.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  39.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=100; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=100; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=100; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=100; total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=100; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  22.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   23.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  23.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  38.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  38.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   37.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 20.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=20.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 18.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=18.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 11.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=11.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 16.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=16.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  22.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 17.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=17.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   22.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  22.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 17.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=17.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   37.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  37.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 16.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=16.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 16.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=16.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed: 15.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=15.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   50.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(verbose=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [300, 500, 1000],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500, 1000]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(verbose=1),\n",
       "             param_grid={&#x27;max_depth&#x27;: [300, 500, 1000],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500, 1000]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(verbose=1),\n",
       "             param_grid={'max_depth': [300, 500, 1000],\n",
       "                         'n_estimators': [100, 300, 500, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(RandomForestClassifier(verbose=1), param_grid, verbose=2)\n",
    "\n",
    "grid.fit(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ab87ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1000, 'n_estimators': 500}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15c696c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8044619422572179"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.score(val_embeddings, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fc280",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9d78d",
   "metadata": {},
   "source": [
    "Due to the time of computing needed to run GridSearchCV on GradientBoostingClassifier with our param_grid, we are going to use HalvingGridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 761\n",
      "max_resources_: 6851\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 12\n",
      "n_resources: 761\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           16.12s\n",
      "         2           1.0389           15.69s\n",
      "         3           0.9093           15.57s\n",
      "         4           0.7998           15.14s\n",
      "         5           0.7062           14.96s\n",
      "         6           0.6256           14.74s\n",
      "         7           0.5557           14.65s\n",
      "         8           0.4948           14.42s\n",
      "         9           0.4414           14.22s\n",
      "        10           0.3944           14.04s\n",
      "        20           0.1353           12.21s\n",
      "        30           0.0486           10.66s\n",
      "        40           0.0177            9.10s\n",
      "        50           0.0065            7.58s\n",
      "        60           0.0024            6.06s\n",
      "        70           0.0009            4.53s\n",
      "        80           0.0003            3.02s\n",
      "        90           0.0001            1.51s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=100; total time=  15.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           18.58s\n",
      "         2           1.0279           17.57s\n",
      "         3           0.8997           17.19s\n",
      "         4           0.7916           16.87s\n",
      "         5           0.6994           16.66s\n",
      "         6           0.6200           16.46s\n",
      "         7           0.5512           16.16s\n",
      "         8           0.4912           15.95s\n",
      "         9           0.4386           15.83s\n",
      "        10           0.3924           15.72s\n",
      "        20           0.1376           13.91s\n",
      "        30           0.0523           12.06s\n",
      "        40           0.0220           10.27s\n",
      "        50           0.0110            8.58s\n",
      "        60           0.0069            6.85s\n",
      "        70           0.0054            5.14s\n",
      "        80           0.0049            3.42s\n",
      "        90           0.0047            1.71s\n",
      "       100           0.0046            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=100; total time=  17.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723           19.31s\n",
      "         2           1.0181           20.60s\n",
      "         3           0.8903           19.48s\n",
      "         4           0.7826           19.18s\n",
      "         5           0.6907           19.56s\n",
      "         6           0.6117           19.78s\n",
      "         7           0.5433           19.17s\n",
      "         8           0.4836           18.67s\n",
      "         9           0.4314           18.27s\n",
      "        10           0.3854           18.21s\n",
      "        20           0.1322           15.47s\n",
      "        30           0.0475           13.55s\n",
      "        40           0.0173           11.48s\n",
      "        50           0.0064            9.62s\n",
      "        60           0.0023            7.69s\n",
      "        70           0.0009            5.73s\n",
      "        80           0.0003            3.80s\n",
      "        90           0.0001            1.90s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=100; total time=  19.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           17.92s\n",
      "         2           1.0321           16.64s\n",
      "         3           0.9031           16.04s\n",
      "         4           0.7941           15.66s\n",
      "         5           0.7011           15.47s\n",
      "         6           0.6211           15.16s\n",
      "         7           0.5516           14.95s\n",
      "         8           0.4911           14.93s\n",
      "         9           0.4381           14.84s\n",
      "        10           0.3914           14.55s\n",
      "        20           0.1342           12.95s\n",
      "        30           0.0482           11.48s\n",
      "        40           0.0176            9.83s\n",
      "        50           0.0065            8.22s\n",
      "        60           0.0024            6.56s\n",
      "        70           0.0009            4.91s\n",
      "        80           0.0003            3.26s\n",
      "        90           0.0001            1.63s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=100; total time=  16.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702           19.35s\n",
      "         2           1.0162           18.98s\n",
      "         3           0.8885           19.61s\n",
      "         4           0.7809           18.16s\n",
      "         5           0.6893           17.22s\n",
      "         6           0.6104           17.03s\n",
      "         7           0.5421           16.49s\n",
      "         8           0.4826           16.61s\n",
      "         9           0.4305           16.12s\n",
      "        10           0.3846           16.05s\n",
      "        20           0.1319           13.73s\n",
      "        30           0.0474           11.93s\n",
      "        40           0.0173           10.06s\n",
      "        50           0.0063            8.50s\n",
      "        60           0.0023            6.76s\n",
      "        70           0.0009            5.03s\n",
      "        80           0.0003            3.36s\n",
      "        90           0.0001            1.67s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=100; total time=  16.8s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           48.41s\n",
      "         2           1.0389           47.27s\n",
      "         3           0.9093           47.73s\n",
      "         4           0.7998           46.66s\n",
      "         5           0.7062           46.45s\n",
      "         6           0.6256           46.08s\n",
      "         7           0.5557           46.14s\n",
      "         8           0.4948           45.72s\n",
      "         9           0.4414           45.38s\n",
      "        10           0.3944           45.09s\n",
      "        20           0.1353           43.05s\n",
      "        30           0.0486           41.06s\n",
      "        40           0.0177           39.53s\n",
      "        50           0.0065           37.88s\n",
      "        60           0.0024           36.26s\n",
      "        70           0.0009           34.77s\n",
      "        80           0.0003           33.20s\n",
      "        90           0.0001           31.72s\n",
      "       100           0.0000           30.18s\n",
      "       200           0.0000           13.11s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  26.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           56.13s\n",
      "         2           1.0279           53.54s\n",
      "         3           0.8997           52.51s\n",
      "         4           0.7916           51.94s\n",
      "         5           0.6994           51.67s\n",
      "         6           0.6200           51.44s\n",
      "         7           0.5512           51.08s\n",
      "         8           0.4912           50.60s\n",
      "         9           0.4386           50.33s\n",
      "        10           0.3924           50.16s\n",
      "        20           0.1376           48.19s\n",
      "        30           0.0523           46.39s\n",
      "        40           0.0220           44.70s\n",
      "        50           0.0110           42.79s\n",
      "        60           0.0069           41.14s\n",
      "        70           0.0054           39.30s\n",
      "        80           0.0049           37.59s\n",
      "        90           0.0047           35.90s\n",
      "       100           0.0046           34.16s\n",
      "       200           0.0046           15.84s\n",
      "       300           0.0046            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  40.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            1.06m\n",
      "         2           1.0181            1.08m\n",
      "         3           0.8903            1.01m\n",
      "         4           0.7826           59.78s\n",
      "         5           0.6907           59.91s\n",
      "         6           0.6117            1.00m\n",
      "         7           0.5433           59.00s\n",
      "         8           0.4836           58.23s\n",
      "         9           0.4314           57.53s\n",
      "        10           0.3854           57.44s\n",
      "        20           0.1322           54.04s\n",
      "        30           0.0475           52.22s\n",
      "        40           0.0173           49.86s\n",
      "        50           0.0064           48.14s\n",
      "        60           0.0023           45.99s\n",
      "        70           0.0009           43.88s\n",
      "        80           0.0003           42.12s\n",
      "        90           0.0001           40.16s\n",
      "       100           0.0000           38.37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       200           0.0000           16.40s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  32.8s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           50.27s\n",
      "         2           1.0321           49.29s\n",
      "         3           0.9031           47.94s\n",
      "         4           0.7941           48.39s\n",
      "         5           0.7011           49.67s\n",
      "         6           0.6211           48.71s\n",
      "         7           0.5516           48.11s\n",
      "         8           0.4911           47.54s\n",
      "         9           0.4381           47.69s\n",
      "        10           0.3914           47.68s\n",
      "        20           0.1342           45.00s\n",
      "        30           0.0482           43.60s\n",
      "        40           0.0176           42.20s\n",
      "        50           0.0065           40.62s\n",
      "        60           0.0024           38.98s\n",
      "        70           0.0009           37.42s\n",
      "        80           0.0003           35.66s\n",
      "        90           0.0001           34.13s\n",
      "       100           0.0000           32.46s\n",
      "       200           0.0000           14.03s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  28.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            1.20m\n",
      "         2           1.0162            1.06m\n",
      "         3           0.8885            1.07m\n",
      "         4           0.7809           59.74s\n",
      "         5           0.6893           58.50s\n",
      "         6           0.6104           57.45s\n",
      "         7           0.5421           55.36s\n",
      "         8           0.4826           55.16s\n",
      "         9           0.4305           53.71s\n",
      "        10           0.3846           53.42s\n",
      "        20           0.1319           48.81s\n",
      "        30           0.0474           46.46s\n",
      "        40           0.0173           44.12s\n",
      "        50           0.0063           42.88s\n",
      "        60           0.0023           40.90s\n",
      "        70           0.0009           38.99s\n",
      "        80           0.0003           37.36s\n",
      "        90           0.0001           35.27s\n",
      "       100           0.0000           33.84s\n",
      "       200           0.0000           14.59s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=300; total time=  29.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            1.33m\n",
      "         2           1.0389            1.29m\n",
      "         3           0.9093            1.33m\n",
      "         4           0.7998            1.31m\n",
      "         5           0.7062            1.30m\n",
      "         6           0.6256            1.28m\n",
      "         7           0.5557            1.29m\n",
      "         8           0.4948            1.29m\n",
      "         9           0.4414            1.28m\n",
      "        10           0.3944            1.27m\n",
      "        20           0.1353            1.22m\n",
      "        30           0.0486            1.19m\n",
      "        40           0.0177            1.16m\n",
      "        50           0.0065            1.13m\n",
      "        60           0.0024            1.11m\n",
      "        70           0.0009            1.08m\n",
      "        80           0.0003            1.06m\n",
      "        90           0.0001            1.03m\n",
      "       100           0.0000            1.00m\n",
      "       200           0.0000           39.61s\n",
      "       300           0.0000           17.61s\n",
      "       400           0.0000            6.61s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  26.4s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821            1.49m\n",
      "         2           1.0279            1.45m\n",
      "         3           0.8997            1.45m\n",
      "         4           0.7916            1.44m\n",
      "         5           0.6994            1.42m\n",
      "         6           0.6200            1.42m\n",
      "         7           0.5512            1.42m\n",
      "         8           0.4912            1.42m\n",
      "         9           0.4386            1.41m\n",
      "        10           0.3924            1.41m\n",
      "        20           0.1376            1.38m\n",
      "        30           0.0523            1.35m\n",
      "        40           0.0220            1.31m\n",
      "        50           0.0110            1.28m\n",
      "        60           0.0069            1.25m\n",
      "        70           0.0054            1.23m\n",
      "        80           0.0049            1.19m\n",
      "        90           0.0047            1.17m\n",
      "       100           0.0046            1.14m\n",
      "       200           0.0046           47.76s\n",
      "       300           0.0046           26.30s\n",
      "       400           0.0046           11.97s\n",
      "       500           0.0046            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  57.8s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            1.58m\n",
      "         2           1.0181            1.71m\n",
      "         3           0.8903            1.65m\n",
      "         4           0.7826            1.64m\n",
      "         5           0.6907            1.66m\n",
      "         6           0.6117            1.70m\n",
      "         7           0.5433            1.66m\n",
      "         8           0.4836            1.64m\n",
      "         9           0.4314            1.61m\n",
      "        10           0.3854            1.60m\n",
      "        20           0.1322            1.57m\n",
      "        30           0.0475            1.52m\n",
      "        40           0.0173            1.47m\n",
      "        50           0.0064            1.44m\n",
      "        60           0.0023            1.41m\n",
      "        70           0.0009            1.38m\n",
      "        80           0.0003            1.35m\n",
      "        90           0.0001            1.31m\n",
      "       100           0.0000            1.29m\n",
      "       200           0.0000           49.39s\n",
      "       300           0.0000           21.96s\n",
      "       400           0.0000            8.24s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  33.0s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            1.34m\n",
      "         2           1.0321            1.32m\n",
      "         3           0.9031            1.31m\n",
      "         4           0.7941            1.34m\n",
      "         5           0.7011            1.33m\n",
      "         6           0.6211            1.32m\n",
      "         7           0.5516            1.31m\n",
      "         8           0.4911            1.30m\n",
      "         9           0.4381            1.31m\n",
      "        10           0.3914            1.31m\n",
      "        20           0.1342            1.27m\n",
      "        30           0.0482            1.26m\n",
      "        40           0.0176            1.24m\n",
      "        50           0.0065            1.22m\n",
      "        60           0.0024            1.19m\n",
      "        70           0.0009            1.16m\n",
      "        80           0.0003            1.14m\n",
      "        90           0.0001            1.11m\n",
      "       100           0.0000            1.08m\n",
      "       200           0.0000           41.61s\n",
      "       300           0.0000           18.50s\n",
      "       400           0.0000            6.94s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  27.8s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            1.73m\n",
      "         2           1.0162            1.65m\n",
      "         3           0.8885            1.66m\n",
      "         4           0.7809            1.55m\n",
      "         5           0.6893            1.54m\n",
      "         6           0.6104            1.53m\n",
      "         7           0.5421            1.48m\n",
      "         8           0.4826            1.49m\n",
      "         9           0.4305            1.46m\n",
      "        10           0.3846            1.46m\n",
      "        20           0.1319            1.39m\n",
      "        30           0.0474            1.32m\n",
      "        40           0.0173            1.28m\n",
      "        50           0.0063            1.27m\n",
      "        60           0.0023            1.23m\n",
      "        70           0.0009            1.20m\n",
      "        80           0.0003            1.17m\n",
      "        90           0.0001            1.14m\n",
      "       100           0.0000            1.11m\n",
      "       200           0.0000           43.51s\n",
      "       300           0.0000           19.34s\n",
      "       400           0.0000            7.26s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=300, n_estimators=500; total time=  29.0s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            2.74m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2           1.0389            2.68m\n",
      "         3           0.9093            2.71m\n",
      "         4           0.7998            2.65m\n",
      "         5           0.7062            2.64m\n",
      "         6           0.6256            2.62m\n",
      "         7           0.5557            2.62m\n",
      "         8           0.4948            2.60m\n",
      "         9           0.4414            2.59m\n",
      "        10           0.3944            2.58m\n",
      "        20           0.1353            2.50m\n",
      "        30           0.0486            2.45m\n",
      "        40           0.0177            2.43m\n",
      "        50           0.0065            2.40m\n",
      "        60           0.0024            2.37m\n",
      "        70           0.0009            2.34m\n",
      "        80           0.0003            2.31m\n",
      "        90           0.0001            2.29m\n",
      "       100           0.0000            2.26m\n",
      "       200           0.0000            1.76m\n",
      "       300           0.0000            1.03m\n",
      "       400           0.0000           39.70s\n",
      "       500           0.0000           26.47s\n",
      "       600           0.0000           17.66s\n",
      "       700           0.0000           11.35s\n",
      "       800           0.0000            6.62s\n",
      "       900           0.0000            2.95s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=  26.5s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821            3.07m\n",
      "         2           1.0279            2.95m\n",
      "         3           0.8997            2.94m\n",
      "         4           0.7916            2.91m\n",
      "         5           0.6994            2.88m\n",
      "         6           0.6200            2.88m\n",
      "         7           0.5512            2.87m\n",
      "         8           0.4912            2.87m\n",
      "         9           0.4386            2.86m\n",
      "        10           0.3924            2.86m\n",
      "        20           0.1376            2.82m\n",
      "        30           0.0523            2.77m\n",
      "        40           0.0220            2.73m\n",
      "        50           0.0110            2.70m\n",
      "        60           0.0069            2.68m\n",
      "        70           0.0054            2.65m\n",
      "        80           0.0049            2.62m\n",
      "        90           0.0047            2.60m\n",
      "       100           0.0046            2.57m\n",
      "       200           0.0046            2.11m\n",
      "       300           0.0046            1.57m\n",
      "       400           0.0046            1.25m\n",
      "       500           0.0046           59.24s\n",
      "       600           0.0046           45.82s\n",
      "       700           0.0046           33.79s\n",
      "       800           0.0046           22.45s\n",
      "       900           0.0046           11.17s\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 3.8min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            3.23m\n",
      "         2           1.0181            3.26m\n",
      "         3           0.8903            3.19m\n",
      "         4           0.7826            3.30m\n",
      "         5           0.6907            3.35m\n",
      "         6           0.6117            3.32m\n",
      "         7           0.5433            3.27m\n",
      "         8           0.4836            3.24m\n",
      "         9           0.4314            3.23m\n",
      "        10           0.3854            3.27m\n",
      "        20           0.1322            3.18m\n",
      "        30           0.0475            3.16m\n",
      "        40           0.0173            3.08m\n",
      "        50           0.0064            3.05m\n",
      "        60           0.0023            3.00m\n",
      "        70           0.0009            2.98m\n",
      "        80           0.0003            2.94m\n",
      "        90           0.0001            2.91m\n",
      "       100           0.0000            2.88m\n",
      "       200           0.0000            2.19m\n",
      "       300           0.0000            1.28m\n",
      "       400           0.0000           49.28s\n",
      "       500           0.0000           32.86s\n",
      "       600           0.0000           21.91s\n",
      "       700           0.0000           14.09s\n",
      "       800           0.0000            8.22s\n",
      "       900           0.0000            3.65s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=  32.9s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            2.79m\n",
      "         2           1.0321            2.72m\n",
      "         3           0.9031            2.66m\n",
      "         4           0.7941            2.63m\n",
      "         5           0.7011            2.63m\n",
      "         6           0.6211            2.60m\n",
      "         7           0.5516            2.60m\n",
      "         8           0.4911            2.63m\n",
      "         9           0.4381            2.65m\n",
      "        10           0.3914            2.67m\n",
      "        20           0.1342            2.62m\n",
      "        30           0.0482            2.62m\n",
      "        40           0.0176            2.59m\n",
      "        50           0.0065            2.58m\n",
      "        60           0.0024            2.55m\n",
      "        70           0.0009            2.52m\n",
      "        80           0.0003            2.49m\n",
      "        90           0.0001            2.46m\n",
      "       100           0.0000            2.43m\n",
      "       200           0.0000            1.87m\n",
      "       300           0.0000            1.09m\n",
      "       400           0.0000           42.19s\n",
      "       500           0.0000           28.13s\n",
      "       600           0.0000           18.76s\n",
      "       700           0.0000           12.06s\n",
      "       800           0.0000            7.04s\n",
      "       900           0.0000            3.13s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=  28.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            3.52m\n",
      "         2           1.0162            3.36m\n",
      "         3           0.8885            3.39m\n",
      "         4           0.7809            3.16m\n",
      "         5           0.6893            3.13m\n",
      "         6           0.6104            3.11m\n",
      "         7           0.5421            3.02m\n",
      "         8           0.4826            3.06m\n",
      "         9           0.4305            2.99m\n",
      "        10           0.3846            2.99m\n",
      "        20           0.1319            2.83m\n",
      "        30           0.0474            2.79m\n",
      "        40           0.0173            2.71m\n",
      "        50           0.0063            2.72m\n",
      "        60           0.0023            2.69m\n",
      "        70           0.0009            2.62m\n",
      "        80           0.0003            2.58m\n",
      "        90           0.0001            2.53m\n",
      "       100           0.0000            2.53m\n",
      "       200           0.0000            1.92m\n",
      "       300           0.0000            1.12m\n",
      "       400           0.0000           43.30s\n",
      "       500           0.0000           28.88s\n",
      "       600           0.0000           19.26s\n",
      "       700           0.0000           12.38s\n",
      "       800           0.0000            7.23s\n",
      "       900           0.0000            3.21s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=  28.9s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           16.26s\n",
      "         2           1.0389           15.57s\n",
      "         3           0.9093           15.58s\n",
      "         4           0.7998           15.14s\n",
      "         5           0.7062           14.93s\n",
      "         6           0.6256           14.68s\n",
      "         7           0.5557           14.61s\n",
      "         8           0.4948           14.39s\n",
      "         9           0.4414           14.16s\n",
      "        10           0.3944           13.99s\n",
      "        20           0.1353           12.30s\n",
      "        30           0.0486           10.66s\n",
      "        40           0.0177            9.10s\n",
      "        50           0.0065            7.59s\n",
      "        60           0.0024            6.05s\n",
      "        70           0.0009            4.54s\n",
      "        80           0.0003            3.02s\n",
      "        90           0.0001            1.51s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=100; total time=  15.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           18.34s\n",
      "         2           1.0279           17.39s\n",
      "         3           0.8997           17.15s\n",
      "         4           0.7916           16.92s\n",
      "         5           0.6994           16.57s\n",
      "         6           0.6200           16.35s\n",
      "         7           0.5512           16.11s\n",
      "         8           0.4912           15.95s\n",
      "         9           0.4386           15.75s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10           0.3924           15.63s\n",
      "        20           0.1376           13.70s\n",
      "        30           0.0523           12.03s\n",
      "        40           0.0220           10.29s\n",
      "        50           0.0110            8.54s\n",
      "        60           0.0069            6.84s\n",
      "        70           0.0054            5.12s\n",
      "        80           0.0049            3.42s\n",
      "        90           0.0047            1.71s\n",
      "       100           0.0046            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=100; total time=  17.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723           18.94s\n",
      "         2           1.0181           20.19s\n",
      "         3           0.8903           19.32s\n",
      "         4           0.7826           19.61s\n",
      "         5           0.6907           19.64s\n",
      "         6           0.6117           19.56s\n",
      "         7           0.5433           19.03s\n",
      "         8           0.4836           18.64s\n",
      "         9           0.4314           18.22s\n",
      "        10           0.3854           18.00s\n",
      "        20           0.1322           15.70s\n",
      "        30           0.0475           13.51s\n",
      "        40           0.0173           11.44s\n",
      "        50           0.0064            9.55s\n",
      "        60           0.0023            7.63s\n",
      "        70           0.0009            5.75s\n",
      "        80           0.0003            3.83s\n",
      "        90           0.0001            1.92s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=100; total time=  19.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           15.81s\n",
      "         2           1.0321           15.64s\n",
      "         3           0.9031           15.37s\n",
      "         4           0.7941           15.56s\n",
      "         5           0.7011           15.83s\n",
      "         6           0.6211           15.41s\n",
      "         7           0.5516           15.17s\n",
      "         8           0.4911           14.93s\n",
      "         9           0.4381           14.86s\n",
      "        10           0.3914           14.57s\n",
      "        20           0.1342           12.91s\n",
      "        30           0.0482           11.38s\n",
      "        40           0.0176            9.75s\n",
      "        50           0.0065            8.19s\n",
      "        60           0.0024            6.55s\n",
      "        70           0.0009            4.90s\n",
      "        80           0.0003            3.27s\n",
      "        90           0.0001            1.63s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=100; total time=  16.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702           18.95s\n",
      "         2           1.0162           18.59s\n",
      "         3           0.8885           19.36s\n",
      "         4           0.7809           17.96s\n",
      "         5           0.6893           17.68s\n",
      "         6           0.6104           17.46s\n",
      "         7           0.5421           16.83s\n",
      "         8           0.4826           16.74s\n",
      "         9           0.4305           16.23s\n",
      "        10           0.3846           16.11s\n",
      "        20           0.1319           13.99s\n",
      "        30           0.0474           11.92s\n",
      "        40           0.0173            9.98s\n",
      "        50           0.0063            8.46s\n",
      "        60           0.0023            6.77s\n",
      "        70           0.0009            5.04s\n",
      "        80           0.0003            3.33s\n",
      "        90           0.0001            1.66s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=100; total time=  16.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           48.37s\n",
      "         2           1.0389           46.89s\n",
      "         3           0.9093           47.62s\n",
      "         4           0.7998           46.62s\n",
      "         5           0.7062           46.42s\n",
      "         6           0.6256           46.05s\n",
      "         7           0.5557           46.12s\n",
      "         8           0.4948           45.71s\n",
      "         9           0.4414           45.44s\n",
      "        10           0.3944           45.20s\n",
      "        20           0.1353           42.76s\n",
      "        30           0.0486           41.16s\n",
      "        40           0.0177           39.46s\n",
      "        50           0.0065           37.97s\n",
      "        60           0.0024           36.35s\n",
      "        70           0.0009           34.87s\n",
      "        80           0.0003           33.29s\n",
      "        90           0.0001           31.80s\n",
      "       100           0.0000           30.25s\n",
      "       200           0.0000           13.22s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  26.5s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           55.29s\n",
      "         2           1.0279           52.71s\n",
      "         3           0.8997           52.26s\n",
      "         4           0.7916           51.97s\n",
      "         5           0.6994           51.28s\n",
      "         6           0.6200           50.99s\n",
      "         7           0.5512           50.76s\n",
      "         8           0.4912           50.53s\n",
      "         9           0.4386           50.28s\n",
      "        10           0.3924           50.36s\n",
      "        20           0.1376           48.52s\n",
      "        30           0.0523           46.49s\n",
      "        40           0.0220           44.69s\n",
      "        50           0.0110           42.84s\n",
      "        60           0.0069           41.05s\n",
      "        70           0.0054           39.34s\n",
      "        80           0.0049           37.59s\n",
      "        90           0.0047           35.93s\n",
      "       100           0.0046           34.19s\n",
      "       200           0.0046           15.84s\n",
      "       300           0.0046            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  39.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723           56.97s\n",
      "         2           1.0181            1.00m\n",
      "         3           0.8903           58.27s\n",
      "         4           0.7826           59.23s\n",
      "         5           0.6907           59.79s\n",
      "         6           0.6117            1.01m\n",
      "         7           0.5433           59.12s\n",
      "         8           0.4836           58.12s\n",
      "         9           0.4314           57.40s\n",
      "        10           0.3854           57.32s\n",
      "        20           0.1322           54.41s\n",
      "        30           0.0475           52.20s\n",
      "        40           0.0173           49.81s\n",
      "        50           0.0064           47.85s\n",
      "        60           0.0023           45.82s\n",
      "        70           0.0009           44.10s\n",
      "        80           0.0003           41.93s\n",
      "        90           0.0001           40.03s\n",
      "       100           0.0000           38.11s\n",
      "       200           0.0000           16.32s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  32.7s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           48.60s\n",
      "         2           1.0321           47.94s\n",
      "         3           0.9031           48.91s\n",
      "         4           0.7941           49.33s\n",
      "         5           0.7011           48.62s\n",
      "         6           0.6211           47.68s\n",
      "         7           0.5516           47.35s\n",
      "         8           0.4911           47.56s\n",
      "         9           0.4381           47.60s\n",
      "        10           0.3914           47.62s\n",
      "        20           0.1342           45.46s\n",
      "        30           0.0482           44.09s\n",
      "        40           0.0176           42.23s\n",
      "        50           0.0065           40.78s\n",
      "        60           0.0024           39.03s\n",
      "        70           0.0009           37.43s\n",
      "        80           0.0003           35.67s\n",
      "        90           0.0001           34.12s\n",
      "       100           0.0000           32.42s\n",
      "       200           0.0000           14.07s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  28.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702           57.05s\n",
      "         2           1.0162           56.56s\n",
      "         3           0.8885           59.31s\n",
      "         4           0.7809           56.14s\n",
      "         5           0.6893           55.65s\n",
      "         6           0.6104           55.24s\n",
      "         7           0.5421           53.77s\n",
      "         8           0.4826           54.30s\n",
      "         9           0.4305           52.96s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10           0.3846           52.78s\n",
      "        20           0.1319           48.71s\n",
      "        30           0.0474           46.16s\n",
      "        40           0.0173           44.26s\n",
      "        50           0.0063           43.04s\n",
      "        60           0.0023           40.85s\n",
      "        70           0.0009           39.24s\n",
      "        80           0.0003           37.51s\n",
      "        90           0.0001           35.72s\n",
      "       100           0.0000           33.91s\n",
      "       200           0.0000           14.69s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=300; total time=  29.4s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            1.34m\n",
      "         2           1.0389            1.31m\n",
      "         3           0.9093            1.34m\n",
      "         4           0.7998            1.31m\n",
      "         5           0.7062            1.30m\n",
      "         6           0.6256            1.29m\n",
      "         7           0.5557            1.29m\n",
      "         8           0.4948            1.28m\n",
      "         9           0.4414            1.28m\n",
      "        10           0.3944            1.27m\n",
      "        20           0.1353            1.22m\n",
      "        30           0.0486            1.19m\n",
      "        40           0.0177            1.16m\n",
      "        50           0.0065            1.14m\n",
      "        60           0.0024            1.11m\n",
      "        70           0.0009            1.08m\n",
      "        80           0.0003            1.06m\n",
      "        90           0.0001            1.03m\n",
      "       100           0.0000            1.01m\n",
      "       200           0.0000           39.45s\n",
      "       300           0.0000           17.54s\n",
      "       400           0.0000            6.58s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  26.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821            1.56m\n",
      "         2           1.0279            1.48m\n",
      "         3           0.8997            1.46m\n",
      "         4           0.7916            1.45m\n",
      "         5           0.6994            1.43m\n",
      "         6           0.6200            1.43m\n",
      "         7           0.5512            1.43m\n",
      "         8           0.4912            1.42m\n",
      "         9           0.4386            1.41m\n",
      "        10           0.3924            1.42m\n",
      "        20           0.1376            1.38m\n",
      "        30           0.0523            1.35m\n",
      "        40           0.0220            1.32m\n",
      "        50           0.0110            1.28m\n",
      "        60           0.0069            1.26m\n",
      "        70           0.0054            1.23m\n",
      "        80           0.0049            1.20m\n",
      "        90           0.0047            1.17m\n",
      "       100           0.0046            1.14m\n",
      "       200           0.0046           47.42s\n",
      "       300           0.0046           26.50s\n",
      "       400           0.0046           12.22s\n",
      "       500           0.0046            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  58.0s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            1.60m\n",
      "         2           1.0181            1.68m\n",
      "         3           0.8903            1.62m\n",
      "         4           0.7826            1.63m\n",
      "         5           0.6907            1.66m\n",
      "         6           0.6117            1.66m\n",
      "         7           0.5433            1.64m\n",
      "         8           0.4836            1.62m\n",
      "         9           0.4314            1.60m\n",
      "        10           0.3854            1.61m\n",
      "        20           0.1322            1.57m\n",
      "        30           0.0475            1.53m\n",
      "        40           0.0173            1.48m\n",
      "        50           0.0064            1.46m\n",
      "        60           0.0023            1.43m\n",
      "        70           0.0009            1.39m\n",
      "        80           0.0003            1.35m\n",
      "        90           0.0001            1.32m\n",
      "       100           0.0000            1.29m\n",
      "       200           0.0000           49.27s\n",
      "       300           0.0000           21.91s\n",
      "       400           0.0000            8.22s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  32.9s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            1.39m\n",
      "         2           1.0321            1.38m\n",
      "         3           0.9031            1.35m\n",
      "         4           0.7941            1.36m\n",
      "         5           0.7011            1.39m\n",
      "         6           0.6211            1.36m\n",
      "         7           0.5516            1.35m\n",
      "         8           0.4911            1.35m\n",
      "         9           0.4381            1.36m\n",
      "        10           0.3914            1.36m\n",
      "        20           0.1342            1.31m\n",
      "        30           0.0482            1.29m\n",
      "        40           0.0176            1.26m\n",
      "        50           0.0065            1.23m\n",
      "        60           0.0024            1.20m\n",
      "        70           0.0009            1.17m\n",
      "        80           0.0003            1.14m\n",
      "        90           0.0001            1.12m\n",
      "       100           0.0000            1.09m\n",
      "       200           0.0000           42.13s\n",
      "       300           0.0000           18.73s\n",
      "       400           0.0000            7.03s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  28.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            1.98m\n",
      "         2           1.0162            1.78m\n",
      "         3           0.8885            1.80m\n",
      "         4           0.7809            1.68m\n",
      "         5           0.6893            1.59m\n",
      "         6           0.6104            1.57m\n",
      "         7           0.5421            1.53m\n",
      "         8           0.4826            1.55m\n",
      "         9           0.4305            1.51m\n",
      "        10           0.3846            1.59m\n",
      "        20           0.1319            1.55m\n",
      "        30           0.0474            1.44m\n",
      "        40           0.0173            1.38m\n",
      "        50           0.0063            1.35m\n",
      "        60           0.0023            1.32m\n",
      "        70           0.0009            1.30m\n",
      "        80           0.0003            1.27m\n",
      "        90           0.0001            1.23m\n",
      "       100           0.0000            1.21m\n",
      "       200           0.0000           45.91s\n",
      "       300           0.0000           20.41s\n",
      "       400           0.0000            7.66s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=  30.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            2.71m\n",
      "         2           1.0389            2.63m\n",
      "         3           0.9093            2.71m\n",
      "         4           0.7998            2.66m\n",
      "         5           0.7062            2.63m\n",
      "         6           0.6256            2.61m\n",
      "         7           0.5557            2.62m\n",
      "         8           0.4948            2.60m\n",
      "         9           0.4414            2.59m\n",
      "        10           0.3944            2.58m\n",
      "        20           0.1353            2.50m\n",
      "        30           0.0486            2.46m\n",
      "        40           0.0177            2.43m\n",
      "        50           0.0065            2.40m\n",
      "        60           0.0024            2.37m\n",
      "        70           0.0009            2.35m\n",
      "        80           0.0003            2.32m\n",
      "        90           0.0001            2.29m\n",
      "       100           0.0000            2.27m\n",
      "       200           0.0000            1.76m\n",
      "       300           0.0000            1.03m\n",
      "       400           0.0000           39.66s\n",
      "       500           0.0000           26.45s\n",
      "       600           0.0000           17.64s\n",
      "       700           0.0000           11.34s\n",
      "       800           0.0000            6.62s\n",
      "       900           0.0000            2.94s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=  26.5s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821            3.04m\n",
      "         2           1.0279            2.94m\n",
      "         3           0.8997            2.93m\n",
      "         4           0.7916            2.91m\n",
      "         5           0.6994            2.90m\n",
      "         6           0.6200            2.89m\n",
      "         7           0.5512            2.87m\n",
      "         8           0.4912            2.88m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         9           0.4386            2.87m\n",
      "        10           0.3924            2.88m\n",
      "        20           0.1376            2.82m\n",
      "        30           0.0523            2.79m\n",
      "        40           0.0220            2.76m\n",
      "        50           0.0110            2.72m\n",
      "        60           0.0069            2.70m\n",
      "        70           0.0054            2.66m\n",
      "        80           0.0049            2.64m\n",
      "        90           0.0047            2.61m\n",
      "       100           0.0046            2.58m\n",
      "       200           0.0046            2.13m\n",
      "       300           0.0046            1.57m\n",
      "       400           0.0046            1.23m\n",
      "       500           0.0046           59.13s\n",
      "       600           0.0046           45.52s\n",
      "       700           0.0046           33.37s\n",
      "       800           0.0046           21.78s\n",
      "       900           0.0046           10.88s\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 7.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            3.23m\n",
      "         2           1.0181            3.41m\n",
      "         3           0.8903            3.30m\n",
      "         4           0.7826            3.45m\n",
      "         5           0.6907            3.49m\n",
      "         6           0.6117            3.51m\n",
      "         7           0.5433            3.44m\n",
      "         8           0.4836            3.38m\n",
      "         9           0.4314            3.34m\n",
      "        10           0.3854            3.34m\n",
      "        20           0.1322            3.19m\n",
      "        30           0.0475            3.12m\n",
      "        40           0.0173            3.08m\n",
      "        50           0.0064            3.05m\n",
      "        60           0.0023            3.01m\n",
      "        70           0.0009            2.97m\n",
      "        80           0.0003            2.93m\n",
      "        90           0.0001            2.89m\n",
      "       100           0.0000            2.86m\n",
      "       200           0.0000            2.19m\n",
      "       300           0.0000            1.28m\n",
      "       400           0.0000           49.32s\n",
      "       500           0.0000           32.89s\n",
      "       600           0.0000           21.93s\n",
      "       700           0.0000           14.10s\n",
      "       800           0.0000            8.23s\n",
      "       900           0.0000            3.66s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=  32.9s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            2.71m\n",
      "         2           1.0321            2.75m\n",
      "         3           0.9031            2.70m\n",
      "         4           0.7941            2.74m\n",
      "         5           0.7011            2.72m\n",
      "         6           0.6211            2.70m\n",
      "         7           0.5516            2.68m\n",
      "         8           0.4911            2.70m\n",
      "         9           0.4381            2.71m\n",
      "        10           0.3914            2.72m\n",
      "        20           0.1342            2.67m\n",
      "        30           0.0482            2.64m\n",
      "        40           0.0176            2.62m\n",
      "        50           0.0065            2.61m\n",
      "        60           0.0024            2.59m\n",
      "        70           0.0009            2.55m\n",
      "        80           0.0003            2.53m\n",
      "        90           0.0001            2.49m\n",
      "       100           0.0000            2.46m\n",
      "       200           0.0000            1.90m\n",
      "       300           0.0000            1.11m\n",
      "       400           0.0000           42.76s\n",
      "       500           0.0000           28.52s\n",
      "       600           0.0000           19.02s\n",
      "       700           0.0000           12.23s\n",
      "       800           0.0000            7.14s\n",
      "       900           0.0000            3.17s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=  28.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            3.22m\n",
      "         2           1.0162            3.20m\n",
      "         3           0.8885            3.29m\n",
      "         4           0.7809            3.10m\n",
      "         5           0.6893            2.98m\n",
      "         6           0.6104            2.99m\n",
      "         7           0.5421            2.93m\n",
      "         8           0.4826            2.99m\n",
      "         9           0.4305            2.93m\n",
      "        10           0.3846            2.94m\n",
      "        20           0.1319            2.82m\n",
      "        30           0.0474            2.77m\n",
      "        40           0.0173            2.72m\n",
      "        50           0.0063            2.70m\n",
      "        60           0.0023            2.69m\n",
      "        70           0.0009            2.65m\n",
      "        80           0.0003            2.63m\n",
      "        90           0.0001            2.59m\n",
      "       100           0.0000            2.58m\n",
      "       200           0.0000            1.98m\n",
      "       300           0.0000            1.15m\n",
      "       400           0.0000           44.52s\n",
      "       500           0.0000           29.69s\n",
      "       600           0.0000           19.80s\n",
      "       700           0.0000           12.73s\n",
      "       800           0.0000            7.43s\n",
      "       900           0.0000            3.30s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=  29.7s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           16.28s\n",
      "         2           1.0389           15.66s\n",
      "         3           0.9093           15.62s\n",
      "         4           0.7998           15.22s\n",
      "         5           0.7062           15.03s\n",
      "         6           0.6256           14.78s\n",
      "         7           0.5557           14.72s\n",
      "         8           0.4948           14.51s\n",
      "         9           0.4414           14.28s\n",
      "        10           0.3944           14.09s\n",
      "        20           0.1353           12.33s\n",
      "        30           0.0486           10.73s\n",
      "        40           0.0177            9.19s\n",
      "        50           0.0065            7.64s\n",
      "        60           0.0024            6.10s\n",
      "        70           0.0009            4.57s\n",
      "        80           0.0003            3.05s\n",
      "        90           0.0001            1.52s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=  15.2s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           18.57s\n",
      "         2           1.0279           17.56s\n",
      "         3           0.8997           17.25s\n",
      "         4           0.7916           16.86s\n",
      "         5           0.6994           16.58s\n",
      "         6           0.6200           16.39s\n",
      "         7           0.5512           16.21s\n",
      "         8           0.4912           16.01s\n",
      "         9           0.4386           15.84s\n",
      "        10           0.3924           15.68s\n",
      "        20           0.1376           13.84s\n",
      "        30           0.0523           12.09s\n",
      "        40           0.0220           10.35s\n",
      "        50           0.0110            8.62s\n",
      "        60           0.0069            6.89s\n",
      "        70           0.0054            5.18s\n",
      "        80           0.0049            3.45s\n",
      "        90           0.0047            1.73s\n",
      "       100           0.0046            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=  17.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723           20.42s\n",
      "         2           1.0181           20.02s\n",
      "         3           0.8903           19.20s\n",
      "         4           0.7826           18.98s\n",
      "         5           0.6907           18.97s\n",
      "         6           0.6117           19.28s\n",
      "         7           0.5433           18.78s\n",
      "         8           0.4836           18.75s\n",
      "         9           0.4314           18.34s\n",
      "        10           0.3854           18.27s\n",
      "        20           0.1322           15.70s\n",
      "        30           0.0475           13.57s\n",
      "        40           0.0173           11.56s\n",
      "        50           0.0064            9.63s\n",
      "        60           0.0023            7.72s\n",
      "        70           0.0009            5.79s\n",
      "        80           0.0003            3.85s\n",
      "        90           0.0001            1.93s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=  19.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           16.00s\n",
      "         2           1.0321           15.70s\n",
      "         3           0.9031           15.35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4           0.7941           15.13s\n",
      "         5           0.7011           15.58s\n",
      "         6           0.6211           15.21s\n",
      "         7           0.5516           14.97s\n",
      "         8           0.4911           14.95s\n",
      "         9           0.4381           14.89s\n",
      "        10           0.3914           14.80s\n",
      "        20           0.1342           12.95s\n",
      "        30           0.0482           11.39s\n",
      "        40           0.0176            9.81s\n",
      "        50           0.0065            8.21s\n",
      "        60           0.0024            6.56s\n",
      "        70           0.0009            4.93s\n",
      "        80           0.0003            3.28s\n",
      "        90           0.0001            1.64s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=  16.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702           23.56s\n",
      "         2           1.0162           21.02s\n",
      "         3           0.8885           21.07s\n",
      "         4           0.7809           19.31s\n",
      "         5           0.6893           18.19s\n",
      "         6           0.6104           17.88s\n",
      "         7           0.5421           17.26s\n",
      "         8           0.4826           17.14s\n",
      "         9           0.4305           16.60s\n",
      "        10           0.3846           16.44s\n",
      "        20           0.1319           14.10s\n",
      "        30           0.0474           12.01s\n",
      "        40           0.0173           10.21s\n",
      "        50           0.0063            8.55s\n",
      "        60           0.0023            6.84s\n",
      "        70           0.0009            5.13s\n",
      "        80           0.0003            3.42s\n",
      "        90           0.0001            1.70s\n",
      "       100           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=100; total time=  17.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945           49.13s\n",
      "         2           1.0389           47.62s\n",
      "         3           0.9093           48.17s\n",
      "         4           0.7998           47.19s\n",
      "         5           0.7062           46.96s\n",
      "         6           0.6256           46.52s\n",
      "         7           0.5557           46.64s\n",
      "         8           0.4948           46.27s\n",
      "         9           0.4414           45.86s\n",
      "        10           0.3944           45.55s\n",
      "        20           0.1353           43.26s\n",
      "        30           0.0486           41.44s\n",
      "        40           0.0177           39.83s\n",
      "        50           0.0065           38.25s\n",
      "        60           0.0024           36.65s\n",
      "        70           0.0009           35.11s\n",
      "        80           0.0003           33.53s\n",
      "        90           0.0001           31.99s\n",
      "       100           0.0000           30.44s\n",
      "       200           0.0000           13.26s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  26.5s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821           55.55s\n",
      "         2           1.0279           53.19s\n",
      "         3           0.8997           52.78s\n",
      "         4           0.7916           52.33s\n",
      "         5           0.6994           52.17s\n",
      "         6           0.6200           51.84s\n",
      "         7           0.5512           51.57s\n",
      "         8           0.4912           51.32s\n",
      "         9           0.4386           51.24s\n",
      "        10           0.3924           51.06s\n",
      "        20           0.1376           48.89s\n",
      "        30           0.0523           46.76s\n",
      "        40           0.0220           44.87s\n",
      "        50           0.0110           43.06s\n",
      "        60           0.0069           41.41s\n",
      "        70           0.0054           39.68s\n",
      "        80           0.0049           38.00s\n",
      "        90           0.0047           36.28s\n",
      "       100           0.0046           34.50s\n",
      "       200           0.0046           15.89s\n",
      "       300           0.0046            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  40.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723           57.20s\n",
      "         2           1.0181            1.01m\n",
      "         3           0.8903           58.81s\n",
      "         4           0.7826           58.61s\n",
      "         5           0.6907           58.99s\n",
      "         6           0.6117           59.76s\n",
      "         7           0.5433           58.68s\n",
      "         8           0.4836           57.86s\n",
      "         9           0.4314           57.61s\n",
      "        10           0.3854           57.93s\n",
      "        20           0.1322           54.95s\n",
      "        30           0.0475           52.21s\n",
      "        40           0.0173           49.76s\n",
      "        50           0.0064           48.18s\n",
      "        60           0.0023           46.04s\n",
      "        70           0.0009           44.18s\n",
      "        80           0.0003           42.31s\n",
      "        90           0.0001           40.29s\n",
      "       100           0.0000           38.50s\n",
      "       200           0.0000           16.63s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  33.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872           55.45s\n",
      "         2           1.0321           51.72s\n",
      "         3           0.9031           49.87s\n",
      "         4           0.7941           49.02s\n",
      "         5           0.7011           50.11s\n",
      "         6           0.6211           49.06s\n",
      "         7           0.5516           48.49s\n",
      "         8           0.4911           48.04s\n",
      "         9           0.4381           48.16s\n",
      "        10           0.3914           48.21s\n",
      "        20           0.1342           45.82s\n",
      "        30           0.0482           44.15s\n",
      "        40           0.0176           42.70s\n",
      "        50           0.0065           41.29s\n",
      "        60           0.0024           39.61s\n",
      "        70           0.0009           37.92s\n",
      "        80           0.0003           36.21s\n",
      "        90           0.0001           34.49s\n",
      "       100           0.0000           32.69s\n",
      "       200           0.0000           14.16s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  28.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            1.03m\n",
      "         2           1.0162           59.47s\n",
      "         3           0.8885            1.00m\n",
      "         4           0.7809           56.84s\n",
      "         5           0.6893           56.22s\n",
      "         6           0.6104           55.70s\n",
      "         7           0.5421           53.95s\n",
      "         8           0.4826           54.06s\n",
      "         9           0.4305           52.82s\n",
      "        10           0.3846           52.72s\n",
      "        20           0.1319           49.23s\n",
      "        30           0.0474           46.92s\n",
      "        40           0.0173           45.03s\n",
      "        50           0.0063           43.41s\n",
      "        60           0.0023           41.41s\n",
      "        70           0.0009           39.50s\n",
      "        80           0.0003           37.55s\n",
      "        90           0.0001           35.66s\n",
      "       100           0.0000           34.17s\n",
      "       200           0.0000           14.64s\n",
      "       300           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=300; total time=  29.3s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            1.37m\n",
      "         2           1.0389            1.33m\n",
      "         3           0.9093            1.35m\n",
      "         4           0.7998            1.32m\n",
      "         5           0.7062            1.31m\n",
      "         6           0.6256            1.30m\n",
      "         7           0.5557            1.31m\n",
      "         8           0.4948            1.30m\n",
      "         9           0.4414            1.29m\n",
      "        10           0.3944            1.29m\n",
      "        20           0.1353            1.24m\n",
      "        30           0.0486            1.20m\n",
      "        40           0.0177            1.18m\n",
      "        50           0.0065            1.15m\n",
      "        60           0.0024            1.12m\n",
      "        70           0.0009            1.09m\n",
      "        80           0.0003            1.07m\n",
      "        90           0.0001            1.04m\n",
      "       100           0.0000            1.02m\n",
      "       200           0.0000           39.65s\n",
      "       300           0.0000           17.63s\n",
      "       400           0.0000            6.61s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  26.5s\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.1821            1.51m\n",
      "         2           1.0279            1.46m\n",
      "         3           0.8997            1.46m\n",
      "         4           0.7916            1.45m\n",
      "         5           0.6994            1.44m\n",
      "         6           0.6200            1.43m\n",
      "         7           0.5512            1.43m\n",
      "         8           0.4912            1.42m\n",
      "         9           0.4386            1.42m\n",
      "        10           0.3924            1.42m\n",
      "        20           0.1376            1.38m\n",
      "        30           0.0523            1.35m\n",
      "        40           0.0220            1.32m\n",
      "        50           0.0110            1.29m\n",
      "        60           0.0069            1.26m\n",
      "        70           0.0054            1.23m\n",
      "        80           0.0049            1.21m\n",
      "        90           0.0047            1.18m\n",
      "       100           0.0046            1.15m\n",
      "       200           0.0046           48.23s\n",
      "       300           0.0046           26.75s\n",
      "       400           0.0046           12.19s\n",
      "       500           0.0046            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  58.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            1.59m\n",
      "         2           1.0181            1.73m\n",
      "         3           0.8903            1.66m\n",
      "         4           0.7826            1.65m\n",
      "         5           0.6907            1.67m\n",
      "         6           0.6117            1.69m\n",
      "         7           0.5433            1.66m\n",
      "         8           0.4836            1.64m\n",
      "         9           0.4314            1.63m\n",
      "        10           0.3854            1.63m\n",
      "        20           0.1322            1.56m\n",
      "        30           0.0475            1.52m\n",
      "        40           0.0173            1.47m\n",
      "        50           0.0064            1.44m\n",
      "        60           0.0023            1.41m\n",
      "        70           0.0009            1.38m\n",
      "        80           0.0003            1.35m\n",
      "        90           0.0001            1.32m\n",
      "       100           0.0000            1.28m\n",
      "       200           0.0000           49.57s\n",
      "       300           0.0000           22.04s\n",
      "       400           0.0000            8.27s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  33.1s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            1.53m\n",
      "         2           1.0321            1.44m\n",
      "         3           0.9031            1.39m\n",
      "         4           0.7941            1.37m\n",
      "         5           0.7011            1.40m\n",
      "         6           0.6211            1.37m\n",
      "         7           0.5516            1.36m\n",
      "         8           0.4911            1.36m\n",
      "         9           0.4381            1.37m\n",
      "        10           0.3914            1.37m\n",
      "        20           0.1342            1.32m\n",
      "        30           0.0482            1.29m\n",
      "        40           0.0176            1.27m\n",
      "        50           0.0065            1.25m\n",
      "        60           0.0024            1.21m\n",
      "        70           0.0009            1.18m\n",
      "        80           0.0003            1.16m\n",
      "        90           0.0001            1.13m\n",
      "       100           0.0000            1.09m\n",
      "       200           0.0000           42.61s\n",
      "       300           0.0000           18.94s\n",
      "       400           0.0000            7.11s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  28.4s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            1.98m\n",
      "         2           1.0162            1.79m\n",
      "         3           0.8885            1.77m\n",
      "         4           0.7809            1.64m\n",
      "         5           0.6893            1.61m\n",
      "         6           0.6104            1.59m\n",
      "         7           0.5421            1.54m\n",
      "         8           0.4826            1.56m\n",
      "         9           0.4305            1.52m\n",
      "        10           0.3846            1.53m\n",
      "        20           0.1319            1.43m\n",
      "        30           0.0474            1.38m\n",
      "        40           0.0173            1.34m\n",
      "        50           0.0063            1.31m\n",
      "        60           0.0023            1.28m\n",
      "        70           0.0009            1.25m\n",
      "        80           0.0003            1.22m\n",
      "        90           0.0001            1.18m\n",
      "       100           0.0000            1.15m\n",
      "       200           0.0000           44.30s\n",
      "       300           0.0000           19.70s\n",
      "       400           0.0000            7.39s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ...................max_depth=1000, n_estimators=500; total time=  29.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1945            2.71m\n",
      "         2           1.0389            2.64m\n",
      "         3           0.9093            2.69m\n",
      "         4           0.7998            2.65m\n",
      "         5           0.7062            2.64m\n",
      "         6           0.6256            2.62m\n",
      "         7           0.5557            2.63m\n",
      "         8           0.4948            2.62m\n",
      "         9           0.4414            2.61m\n",
      "        10           0.3944            2.59m\n",
      "        20           0.1353            2.52m\n",
      "        30           0.0486            2.48m\n",
      "        40           0.0177            2.45m\n",
      "        50           0.0065            2.42m\n",
      "        60           0.0024            2.39m\n",
      "        70           0.0009            2.36m\n",
      "        80           0.0003            2.33m\n",
      "        90           0.0001            2.31m\n",
      "       100           0.0000            2.28m\n",
      "       200           0.0000            1.77m\n",
      "       300           0.0000            1.03m\n",
      "       400           0.0000           39.79s\n",
      "       500           0.0000           26.53s\n",
      "       600           0.0000           17.69s\n",
      "       700           0.0000           11.38s\n",
      "       800           0.0000            6.64s\n",
      "       900           0.0000            2.95s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time=  26.6s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1821            3.12m\n",
      "         2           1.0279            2.98m\n",
      "         3           0.8997            2.96m\n",
      "         4           0.7916            2.94m\n",
      "         5           0.6994            2.93m\n",
      "         6           0.6200            2.92m\n",
      "         7           0.5512            2.91m\n",
      "         8           0.4912            2.90m\n",
      "         9           0.4386            2.90m\n",
      "        10           0.3924            2.90m\n",
      "        20           0.1376            2.84m\n",
      "        30           0.0523            2.80m\n",
      "        40           0.0220            2.77m\n",
      "        50           0.0110            2.74m\n",
      "        60           0.0069            2.71m\n",
      "        70           0.0054            2.68m\n",
      "        80           0.0049            2.65m\n",
      "        90           0.0047            2.62m\n",
      "       100           0.0046            2.59m\n",
      "       200           0.0046            2.14m\n",
      "       300           0.0046            1.58m\n",
      "       400           0.0046            1.24m\n",
      "       500           0.0046           59.81s\n",
      "       600           0.0046           46.85s\n",
      "       700           0.0046           34.29s\n",
      "       800           0.0046           22.28s\n",
      "       900           0.0046           11.03s\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 8.6min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1723            3.22m\n",
      "         2           1.0181            3.60m\n",
      "         3           0.8903            3.42m\n",
      "         4           0.7826            3.38m\n",
      "         5           0.6907            3.42m\n",
      "         6           0.6117            3.43m\n",
      "         7           0.5433            3.37m\n",
      "         8           0.4836            3.39m\n",
      "         9           0.4314            3.35m\n",
      "        10           0.3854            3.36m\n",
      "        20           0.1322            3.22m\n",
      "        30           0.0475            3.19m\n",
      "        40           0.0173            3.12m\n",
      "        50           0.0064            3.09m\n",
      "        60           0.0023            3.04m\n",
      "        70           0.0009            3.01m\n",
      "        80           0.0003            2.97m\n",
      "        90           0.0001            2.94m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       100           0.0000            2.90m\n",
      "       200           0.0000            2.22m\n",
      "       300           0.0000            1.30m\n",
      "       400           0.0000           49.97s\n",
      "       500           0.0000           33.32s\n",
      "       600           0.0000           22.22s\n",
      "       700           0.0000           14.29s\n",
      "       800           0.0000            8.34s\n",
      "       900           0.0000            3.71s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time=  33.4s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1872            2.73m\n",
      "         2           1.0321            2.71m\n",
      "         3           0.9031            2.67m\n",
      "         4           0.7941            2.65m\n",
      "         5           0.7011            2.65m\n",
      "         6           0.6211            2.62m\n",
      "         7           0.5516            2.62m\n",
      "         8           0.4911            2.61m\n",
      "         9           0.4381            2.63m\n",
      "        10           0.3914            2.65m\n",
      "        20           0.1342            2.64m\n",
      "        30           0.0482            2.64m\n",
      "        40           0.0176            2.61m\n",
      "        50           0.0065            2.60m\n",
      "        60           0.0024            2.58m\n",
      "        70           0.0009            2.54m\n",
      "        80           0.0003            2.51m\n",
      "        90           0.0001            2.48m\n",
      "       100           0.0000            2.45m\n",
      "       200           0.0000            1.89m\n",
      "       300           0.0000            1.10m\n",
      "       400           0.0000           42.55s\n",
      "       500           0.0000           28.37s\n",
      "       600           0.0000           18.92s\n",
      "       700           0.0000           12.17s\n",
      "       800           0.0000            7.10s\n",
      "       900           0.0000            3.16s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time=  28.4s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1702            3.75m\n",
      "         2           1.0162            3.48m\n",
      "         3           0.8885            3.56m\n",
      "         4           0.7809            3.30m\n",
      "         5           0.6893            3.14m\n",
      "         6           0.6104            3.13m\n",
      "         7           0.5421            3.05m\n",
      "         8           0.4826            3.07m\n",
      "         9           0.4305            3.00m\n",
      "        10           0.3846            3.02m\n",
      "        20           0.1319            2.88m\n",
      "        30           0.0474            2.79m\n",
      "        40           0.0173            2.71m\n",
      "        50           0.0063            2.72m\n",
      "        60           0.0023            2.70m\n",
      "        70           0.0009            2.65m\n",
      "        80           0.0003            2.61m\n",
      "        90           0.0001            2.56m\n",
      "       100           0.0000            2.55m\n",
      "       200           0.0000            1.96m\n",
      "       300           0.0000            1.15m\n",
      "       400           0.0000           44.20s\n",
      "       500           0.0000           29.47s\n",
      "       600           0.0000           19.65s\n",
      "       700           0.0000           12.64s\n",
      "       800           0.0000            7.37s\n",
      "       900           0.0000            3.28s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time=  29.5s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 4\n",
      "n_resources: 2283\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1809            8.03m\n",
      "         2           1.0264            8.48m\n",
      "         3           0.8980            8.52m\n",
      "         4           0.7897            8.40m\n",
      "         5           0.6973            8.28m\n",
      "         6           0.6178            8.23m\n",
      "         7           0.5489            8.22m\n",
      "         8           0.4888            8.16m\n",
      "         9           0.4362            8.14m\n",
      "        10           0.3899            8.69m\n",
      "        20           0.1347            8.12m\n",
      "        30           0.0494            7.88m\n",
      "        40           0.0190            7.63m\n",
      "        50           0.0079            7.44m\n",
      "        60           0.0039            7.26m\n",
      "        70           0.0024            7.06m\n",
      "        80           0.0018            6.88m\n",
      "        90           0.0016            6.72m\n",
      "       100           0.0016            6.54m\n",
      "       200           0.0015            4.26m\n",
      "       300           0.0015            2.32m\n",
      "       400           0.0015            1.05m\n",
      "       500           0.0015            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time= 5.0min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1833            7.07m\n",
      "         2           1.0289            6.88m\n",
      "         3           0.9005            7.06m\n",
      "         4           0.7922            6.97m\n",
      "         5           0.6998            6.94m\n",
      "         6           0.6202            6.91m\n",
      "         7           0.5513            6.86m\n",
      "         8           0.4912            6.86m\n",
      "         9           0.4385            6.80m\n",
      "        10           0.3922            6.76m\n",
      "        20           0.1369            7.33m\n",
      "        30           0.0515            6.86m\n",
      "        40           0.0211            6.55m\n",
      "        50           0.0100            6.32m\n",
      "        60           0.0060            6.12m\n",
      "        70           0.0045            5.94m\n",
      "        80           0.0039            5.77m\n",
      "        90           0.0037            5.61m\n",
      "       100           0.0037            5.45m\n",
      "       200           0.0036           26.86m\n",
      "       300           0.0036           18.90m\n",
      "       400           0.0036           11.34m\n",
      "       500           0.0036            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time=62.9min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1824            7.79m\n",
      "         2           1.0282            7.61m\n",
      "         3           0.9000            7.47m\n",
      "         4           0.7918            7.53m\n",
      "         5           0.6996            7.44m\n",
      "         6           0.6202            7.36m\n",
      "         7           0.5513            7.31m\n",
      "         8           0.4913            7.27m\n",
      "         9           0.4387            7.23m\n",
      "        10           0.3925            7.20m\n",
      "        20           0.1376            7.07m\n",
      "        30           0.0524            6.86m\n",
      "        40           0.0220            6.69m\n",
      "        50           0.0109            6.52m\n",
      "        60           0.0069            6.36m\n",
      "        70           0.0054            6.21m\n",
      "        80           0.0049            6.05m\n",
      "        90           0.0047            5.91m\n",
      "       100           0.0046            5.76m\n",
      "       200           0.0046            3.95m\n",
      "       300           0.0046            2.36m\n",
      "       400           0.0046            1.13m\n",
      "       500           0.0046            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time= 5.5min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1755            6.42m\n",
      "         2           1.0214            6.44m\n",
      "         3           0.8934            6.44m\n",
      "         4           0.7855            6.43m\n",
      "         5           0.6936            6.36m\n",
      "         6           0.6145            6.33m\n",
      "         7           0.5459            6.27m\n",
      "         8           0.4861            6.25m\n",
      "         9           0.4338            6.23m\n",
      "        10           0.3877            6.20m\n",
      "        20           0.1340            6.03m\n",
      "        30           0.0491            5.84m\n",
      "        40           0.0189            5.72m\n",
      "        50           0.0079            5.57m\n",
      "        60           0.0039            5.46m\n",
      "        70           0.0024            5.32m\n",
      "        80           0.0018            5.21m\n",
      "        90           0.0016            5.08m\n",
      "       100           0.0016            4.95m\n",
      "       200           0.0015            3.32m\n",
      "       300           0.0015            1.86m\n",
      "       400           0.0015           53.93s\n",
      "       500           0.0015            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time= 4.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1801            6.13m\n",
      "         2           1.0255            6.14m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3           0.8970            6.27m\n",
      "         4           0.7886            6.18m\n",
      "         5           0.6962            6.18m\n",
      "         6           0.6166            6.13m\n",
      "         7           0.5477            6.09m\n",
      "         8           0.4876            6.07m\n",
      "         9           0.4349            6.09m\n",
      "        10           0.3886            6.06m\n",
      "        20           0.1333            5.85m\n",
      "        30           0.0479            5.63m\n",
      "        40           0.0175            5.50m\n",
      "        50           0.0064            5.37m\n",
      "        60           0.0024            5.26m\n",
      "        70           0.0009            5.13m\n",
      "        80           0.0003            5.02m\n",
      "        90           0.0001            4.90m\n",
      "       100           0.0000            4.78m\n",
      "       200           0.0000            3.12m\n",
      "       300           0.0000            1.39m\n",
      "       400           0.0000           31.22s\n",
      "       500           0.0000            0.00s\n",
      "[CV] END ....................max_depth=500, n_estimators=500; total time= 2.1min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1809           16.07m\n",
      "         2           1.0264           16.82m\n",
      "         3           0.8980           16.91m\n",
      "         4           0.7897           16.66m\n",
      "         5           0.6973           16.49m\n",
      "         6           0.6178           16.38m\n",
      "         7           0.5489           16.40m\n",
      "         8           0.4888           16.28m\n",
      "         9           0.4362           16.28m\n",
      "        10           0.3899           17.66m\n",
      "        20           0.1347           16.62m\n",
      "        30           0.0494           16.11m\n",
      "        40           0.0190           15.83m\n",
      "        50           0.0079           15.54m\n",
      "        60           0.0039           15.34m\n",
      "        70           0.0024           15.15m\n",
      "        80           0.0018           14.95m\n",
      "        90           0.0016           14.72m\n",
      "       100           0.0016           14.53m\n",
      "       200           0.0015           11.40m\n",
      "       300           0.0015            8.06m\n",
      "       400           0.0015            6.31m\n",
      "       500           0.0015            4.98m\n",
      "       600           0.0015            3.85m\n",
      "       700           0.0015            2.85m\n",
      "       800           0.0015            1.88m\n",
      "       900           0.0015           55.59s\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 9.1min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1833           14.11m\n",
      "         2           1.0289           13.74m\n",
      "         3           0.9005           14.13m\n",
      "         4           0.7922           13.93m\n",
      "         5           0.6998           13.88m\n",
      "         6           0.6202           13.86m\n",
      "         7           0.5513           13.78m\n",
      "         8           0.4912           13.80m\n",
      "         9           0.4385           13.69m\n",
      "        10           0.3922           13.63m\n",
      "        20           0.1369           14.78m\n",
      "        30           0.0515           14.00m\n",
      "        40           0.0211           13.53m\n",
      "        50           0.0100           13.23m\n",
      "        60           0.0060           12.95m\n",
      "        70           0.0045           12.74m\n",
      "        80           0.0039           12.55m\n",
      "        90           0.0037           12.35m\n",
      "       100           0.0037           12.19m\n",
      "       200           0.0036            9.70m\n",
      "       300           0.0036            7.40m\n",
      "       400           0.0036            5.94m\n",
      "       500           0.0036            4.80m\n",
      "       600           0.0036            3.77m\n",
      "       700           0.0036            2.78m\n",
      "       800           0.0036            1.84m\n",
      "       900           0.0036           55.00s\n",
      "      1000           0.0036            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time= 9.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1824           15.55m\n",
      "         2           1.0282           15.34m\n",
      "         3           0.9000           15.20m\n",
      "         4           0.7918           15.38m\n",
      "         5           0.6996           15.20m\n",
      "         6           0.6202           15.07m\n",
      "         7           0.5513           15.00m\n",
      "         8           0.4913           14.93m\n",
      "         9           0.4387           14.86m\n",
      "        10           0.3925           14.81m\n",
      "        20           0.1376           14.48m\n",
      "        30           0.0524           14.26m\n",
      "        40           0.0220           14.10m\n",
      "        50           0.0109           13.93m\n",
      "        60           0.0069           13.77m\n",
      "        70           0.0054           13.62m\n",
      "        80           0.0049           13.45m\n",
      "        90           0.0047           13.30m\n",
      "       100           0.0046           13.14m\n",
      "       200           0.0046           10.72m\n",
      "       300           0.0046            8.29m\n",
      "       400           0.0046            6.79m\n",
      "       500           0.0046            5.56m\n",
      "       600           0.0046            4.39m\n",
      "       700           0.0046            3.23m\n",
      "       800           0.0046            2.15m\n",
      "       900           0.0046            1.57m\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=30.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1755           13.00m\n",
      "         2           1.0214           13.01m\n",
      "         3           0.8934           13.15m\n",
      "         4           0.7855           13.06m\n",
      "         5           0.6936           12.98m\n",
      "         6           0.6145           12.85m\n",
      "         7           0.5459           12.81m\n",
      "         8           0.4861           12.77m\n",
      "         9           0.4338           12.72m\n",
      "        10           0.3877           12.68m\n",
      "        20           0.1340           12.43m\n",
      "        30           0.0491           12.22m\n",
      "        40           0.0189           12.05m\n",
      "        50           0.0079          339.17m\n",
      "        60           0.0039          281.59m\n",
      "        70           0.0024          240.42m\n",
      "        80           0.0018          209.52m\n",
      "        90           0.0016          185.45m\n",
      "       100           0.0016          166.17m\n",
      "       200           0.0015          141.29m\n",
      "       300           0.0015           83.72m\n",
      "       400           0.0015           54.94m\n",
      "       500           0.0015           53.70m\n",
      "       600           0.0015           36.36m\n",
      "       700           0.0015           26.66m\n",
      "       800           0.0015           15.74m\n",
      "       900           0.0015            8.87m\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ..................max_depth=500, n_estimators=1000; total time=112.6min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1801           13.14m\n",
      "         2           1.0255           12.97m\n",
      "         3           0.8970           18.11m\n",
      "         4           0.7886           16.51m\n",
      "         5           0.6962           15.79m\n",
      "         6           0.6166           15.11m\n",
      "         7           0.5477           14.60m\n",
      "         8           0.4876           14.33m\n",
      "         9           0.4349           14.02m\n",
      "        10           0.3886           13.79m\n",
      "        20           0.1333           12.65m\n",
      "        30           0.0479           12.14m\n",
      "        40           0.0175           11.86m\n",
      "        50           0.0064           11.63m\n",
      "        60           0.0024           11.49m\n",
      "        70           0.0009           11.29m\n",
      "        80           0.0003           11.15m\n",
      "        90           0.0001          175.83m\n",
      "       100           0.0000          157.56m\n",
      "       200           0.0000           73.53m\n",
      "       300           0.0000           42.89m\n",
      "       400           0.0000           27.57m\n",
      "       500           0.0000           18.38m\n",
      "       600           0.0000           12.26m\n",
      "       700           0.0000            7.88m\n",
      "       800           0.0000            4.60m\n",
      "       900           0.0000            2.04m\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=500, n_estimators=1000; total time=18.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1809           15.79m\n",
      "         2           1.0264           16.68m\n",
      "         3           0.8980           16.77m\n",
      "         4           0.7897           16.54m\n",
      "         5           0.6973           16.33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6           0.6178           16.25m\n",
      "         7           0.5489           16.25m\n",
      "         8           0.4888           16.15m\n",
      "         9           0.4362           16.14m\n",
      "        10           0.3899           17.38m\n",
      "        20           0.1347           16.34m\n",
      "        30           0.0494           15.81m\n",
      "        40           0.0190           15.53m\n",
      "        50           0.0079           15.34m\n",
      "        60           0.0039           15.15m\n",
      "        70           0.0024           14.94m\n",
      "        80           0.0018           14.74m\n",
      "        90           0.0016           14.56m\n",
      "       100           0.0016           14.39m\n",
      "       200           0.0015           11.17m\n",
      "       300           0.0015            7.90m\n",
      "       400           0.0015            6.20m\n",
      "       500           0.0015            4.90m\n",
      "       600           0.0015            3.83m\n",
      "       700           0.0015            2.82m\n",
      "       800           0.0015            1.84m\n",
      "       900           0.0015           54.05s\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 8.9min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1833           13.99m\n",
      "         2           1.0289           13.65m\n",
      "         3           0.9005           14.05m\n",
      "         4           0.7922           13.85m\n",
      "         5           0.6998           13.80m\n",
      "         6           0.6202           13.75m\n",
      "         7           0.5513           13.64m\n",
      "         8           0.4912           13.65m\n",
      "         9           0.4385           13.55m\n",
      "        10           0.3922           13.49m\n",
      "        20           0.1369           14.87m\n",
      "        30           0.0515           14.03m\n",
      "        40           0.0211           13.52m\n",
      "        50           0.0100           13.20m\n",
      "        60           0.0060           12.92m\n",
      "        70           0.0045           12.71m\n",
      "        80           0.0039           12.49m\n",
      "        90           0.0037           12.30m\n",
      "       100           0.0037           12.11m\n",
      "       200           0.0036            9.58m\n",
      "       300           0.0036            7.27m\n",
      "       400           0.0036            5.91m\n",
      "       500           0.0036            4.76m\n",
      "       600           0.0036            3.75m\n",
      "       700           0.0036            2.78m\n",
      "       800           0.0036            1.84m\n",
      "       900           0.0036           54.73s\n",
      "      1000           0.0036            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 9.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1824           15.74m\n",
      "         2           1.0282           15.59m\n",
      "         3           0.9000           15.32m\n",
      "         4           0.7918           15.47m\n",
      "         5           0.6996           15.32m\n",
      "         6           0.6202           15.14m\n",
      "         7           0.5513           15.04m\n",
      "         8           0.4913           14.92m\n",
      "         9           0.4387           14.81m\n",
      "        10           0.3925           14.73m\n",
      "        20           0.1376           14.31m\n",
      "        30           0.0524           14.06m\n",
      "        40           0.0220           13.88m\n",
      "        50           0.0109           13.70m\n",
      "        60           0.0069           13.57m\n",
      "        70           0.0054           13.44m\n",
      "        80           0.0049           13.28m\n",
      "        90           0.0047           13.15m\n",
      "       100           0.0046           12.99m\n",
      "       200           0.0046           10.50m\n",
      "       300           0.0046            8.26m\n",
      "       400           0.0046            6.80m\n",
      "       500           0.0046            5.54m\n",
      "       600           0.0046            4.31m\n",
      "       700           0.0046            3.22m\n",
      "       800           0.0046            2.14m\n",
      "       900           0.0046            1.88m\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END .................max_depth=1000, n_estimators=1000; total time=101.5min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1755           12.69m\n",
      "         2           1.0214           12.74m\n",
      "         3           0.8934           12.89m\n",
      "         4           0.7855           12.82m\n",
      "         5           0.6936           12.78m\n",
      "         6           0.6145           12.65m\n",
      "         7           0.5459           12.60m\n",
      "         8           0.4861           12.59m\n",
      "         9           0.4338           12.56m\n",
      "        10           0.3877           12.51m\n",
      "        20           0.1340           12.25m\n",
      "        30           0.0491           12.11m\n",
      "        40           0.0189           11.94m\n",
      "        50           0.0079           11.77m\n",
      "        60           0.0039           11.68m\n",
      "        70           0.0024           11.53m\n",
      "        80           0.0018           11.42m\n",
      "        90           0.0016           11.28m\n",
      "       100           0.0016           11.17m\n",
      "       200           0.0015            8.90m\n",
      "       300           0.0015            6.56m\n",
      "       400           0.0015            5.30m\n",
      "       500           0.0015            4.34m\n",
      "       600           0.0015            3.47m\n",
      "       700           0.0015            2.58m\n",
      "       800           0.0015            1.70m\n",
      "       900           0.0015           51.06s\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 8.5min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1801           12.47m\n",
      "         2           1.0255           12.47m\n",
      "         3           0.8970           13.04m\n",
      "         4           0.7886           12.74m\n",
      "         5           0.6962           12.71m\n",
      "         6           0.6166           12.52m\n",
      "         7           0.5477           12.46m\n",
      "         8           0.4876           12.42m\n",
      "         9           0.4349           12.38m\n",
      "        10           0.3886           12.32m\n",
      "        20           0.1333           11.96m\n",
      "        30           0.0479           11.85m\n",
      "        40           0.0175           11.67m\n",
      "        50           0.0064           11.47m\n",
      "        60           0.0024           11.33m\n",
      "        70           0.0009           11.19m\n",
      "        80           0.0003           11.06m\n",
      "        90           0.0001           10.92m\n",
      "       100           0.0000           10.79m\n",
      "       200           0.0000            8.34m\n",
      "       300           0.0000            4.86m\n",
      "       400           0.0000            3.13m\n",
      "       500           0.0000            2.08m\n",
      "       600           0.0000            1.39m\n",
      "       700           0.0000           53.62s\n",
      "       800           0.0000           31.28s\n",
      "       900           0.0000           13.90s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ..................max_depth=1000, n_estimators=1000; total time= 2.1min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1809           15.86m\n",
      "         2           1.0264           16.78m\n",
      "         3           0.8980           16.97m\n",
      "         4           0.7897           16.77m\n",
      "         5           0.6973           16.51m\n",
      "         6           0.6178           16.41m\n",
      "         7           0.5489           16.43m\n",
      "         8           0.4888           16.32m\n",
      "         9           0.4362           16.33m\n",
      "        10           0.3899           17.36m\n",
      "        20           0.1347           16.34m\n",
      "        30           0.0494           16.04m\n",
      "        40           0.0190           15.70m\n",
      "        50           0.0079           15.54m\n",
      "        60           0.0039           15.34m\n",
      "        70           0.0024           15.18m\n",
      "        80           0.0018           14.94m\n",
      "        90           0.0016           14.76m\n",
      "       100           0.0016           14.60m\n",
      "       200           0.0015           11.28m\n",
      "       300           0.0015            7.88m\n",
      "       400           0.0015            6.12m\n",
      "       500           0.0015            4.90m\n",
      "       600           0.0015            3.81m\n",
      "       700           0.0015            2.77m\n",
      "       800           0.0015            1.84m\n",
      "       900           0.0015           54.82s\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 9.0min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1833           14.03m\n",
      "         2           1.0289           13.67m\n",
      "         3           0.9005           14.08m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4           0.7922           13.89m\n",
      "         5           0.6998           13.85m\n",
      "         6           0.6202           13.84m\n",
      "         7           0.5513           13.76m\n",
      "         8           0.4912           13.77m\n",
      "         9           0.4385           13.67m\n",
      "        10           0.3922           13.60m\n",
      "        20           0.1369           14.95m\n",
      "        30           0.0515           14.13m\n",
      "        40           0.0211           13.64m\n",
      "        50           0.0100           13.30m\n",
      "        60           0.0060           13.04m\n",
      "        70           0.0045           12.81m\n",
      "        80           0.0039           12.60m\n",
      "        90           0.0037           12.41m\n",
      "       100           0.0037           12.24m\n",
      "       200           0.0036            9.75m\n",
      "       300           0.0036            7.40m\n",
      "       400           0.0036            6.04m\n",
      "       500           0.0036            4.90m\n",
      "       600           0.0036            3.87m\n",
      "       700           0.0036            2.84m\n",
      "       800           0.0036            1.88m\n",
      "       900           0.0036           55.84s\n",
      "      1000           0.0036            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 9.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1824           15.66m\n",
      "         2           1.0282           15.41m\n",
      "         3           0.9000           15.17m\n",
      "         4           0.7918           15.37m\n",
      "         5           0.6996           15.22m\n",
      "         6           0.6202           15.08m\n",
      "         7           0.5513           14.99m\n",
      "         8           0.4913           14.92m\n",
      "         9           0.4387           14.88m\n",
      "        10           0.3925           14.83m\n",
      "        20           0.1376           14.48m\n",
      "        30           0.0524           14.23m\n",
      "        40           0.0220           14.03m\n",
      "        50           0.0109           13.89m\n",
      "        60           0.0069           13.73m\n",
      "        70           0.0054           13.58m\n",
      "        80           0.0049           13.40m\n",
      "        90           0.0047           13.25m\n",
      "       100           0.0046           13.11m\n",
      "       200           0.0046           10.71m\n",
      "       300           0.0046            8.32m\n",
      "       400           0.0046            6.82m\n",
      "       500           0.0046            5.53m\n",
      "       600           0.0046            4.37m\n",
      "       700           0.0046            3.24m\n",
      "       800           0.0046            2.15m\n",
      "       900           0.0046            1.32m\n",
      "      1000           0.0046            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=19.6min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1755           13.12m\n",
      "         2           1.0214           13.05m\n",
      "         3           0.8934           13.15m\n",
      "         4           0.7855           13.06m\n",
      "         5           0.6936           12.91m\n",
      "         6           0.6145           12.79m\n",
      "         7           0.5459           12.72m\n",
      "         8           0.4861           12.69m\n",
      "         9           0.4338           12.66m\n",
      "        10           0.3877           12.62m\n",
      "        20           0.1340           12.43m\n",
      "        30           0.0491           12.22m\n",
      "        40           0.0189           12.06m\n",
      "        50           0.0079           11.92m\n",
      "        60           0.0039           11.79m\n",
      "        70           0.0024           11.65m\n",
      "        80           0.0018           11.53m\n",
      "        90           0.0016           11.40m\n",
      "       100           0.0016           11.27m\n",
      "       200           0.0015           13.37m\n",
      "       300           0.0015            9.12m\n",
      "       400           0.0015           31.32m\n",
      "       500           0.0015           32.02m\n",
      "       600           0.0015           21.94m\n",
      "       700           0.0015           14.46m\n",
      "       800           0.0015            8.63m\n",
      "       900           0.0015            3.93m\n",
      "      1000           0.0015            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time=36.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1801           12.74m\n",
      "         2           1.0255           12.80m\n",
      "         3           0.8970           13.00m\n",
      "         4           0.7886           12.65m\n",
      "         5           0.6962           12.55m\n",
      "         6           0.6166           12.35m\n",
      "         7           0.5477           12.38m\n",
      "         8           0.4876           12.35m\n",
      "         9           0.4349           12.42m\n",
      "        10           0.3886           12.31m\n",
      "        20           0.1333           11.93m\n",
      "        30           0.0479           11.72m\n",
      "        40           0.0175           11.55m\n",
      "        50           0.0064           11.38m\n",
      "        60           0.0024           11.25m\n",
      "        70           0.0009           11.10m\n",
      "        80           0.0003           11.01m\n",
      "        90           0.0001           10.88m\n",
      "       100           0.0000           10.76m\n",
      "       200           0.0000            8.30m\n",
      "       300           0.0000            4.84m\n",
      "       400           0.0000            3.11m\n",
      "       500           0.0000            2.08m\n",
      "       600           0.0000            1.38m\n",
      "       700           0.0000           53.41s\n",
      "       800           0.0000           31.16s\n",
      "       900           0.0000           13.85s\n",
      "      1000           0.0000            0.00s\n",
      "[CV] END ...................max_depth=300, n_estimators=1000; total time= 2.1min\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 6849\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1768           75.53m\n",
      "         2           1.0233           75.06m\n",
      "         3           0.8958           75.49m\n",
      "         4           0.7883          118.95m\n",
      "         5           0.6967          110.36m\n",
      "         6           0.6179          104.70m\n",
      "         7           0.5496          100.41m\n",
      "         8           0.4900           97.23m\n",
      "         9           0.4379           94.37m\n",
      "        10           0.3920           92.41m\n",
      "        20           0.1392           82.17m\n",
      "        30           0.0547           78.86m\n",
      "        40           0.0246           76.55m\n",
      "        50           0.0136           74.45m\n",
      "        60           0.0096           72.80m\n",
      "        70           0.0081           71.52m\n",
      "        80           0.0076           70.29m\n",
      "        90           0.0074           69.23m\n",
      "       100           0.0073           68.19m\n",
      "       200           0.0073           55.13m\n",
      "       300           0.0073           45.89m\n",
      "       400           0.0073           38.32m\n",
      "       500           0.0073           31.38m\n",
      "       600           0.0073           24.71m\n",
      "       700           0.0073           20.01m\n",
      "       800           0.0073           78.89m\n"
     ]
    }
   ],
   "source": [
    "grid = HalvingGridSearchCV(GradientBoostingClassifier(verbose=1), param_grid, verbose=2)\n",
    "\n",
    "grid.fit(embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0eca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(val_embeddings, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193eac57",
   "metadata": {},
   "source": [
    "# Fine-Tuning BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc743022",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.text.values\n",
    "labels = data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3473144",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba931b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 84\n",
    "\n",
    "#Padding the input to the max length that is 84\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "# Performing same steps on the attention masks\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ed326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the input data to the tensor , which can be feeded to the model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the DataLoader which will help us to load data into the GPU/CPU\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535320ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 2,   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66747699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the helper function to have a watch on elapsed time\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start the training process\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de633a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c9386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4035d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3cd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
